---
layout: default
---

[[Google Scholar](https://scholar.google.com/citations?hl=en&user=5e9tBtQAAAAJ&view_op=list_works&gmla=AJsN-F6ieV5-6P_WzCdbvRYvxWSI33-VELtb0CU6B5dRbXHRE5PhOLn2bmG_5XkhAUdOEgKxiZd864yv2IVcuooJbWq6x7N7lL1nm_vxeK_QPHLncFhdjSA)]&emsp;[[Twitter](https://twitter.com/YangyiChen6666)]&emsp;[[Github](https://github.com/Yangyi-Chen)]



<!-- google-site-verification: google839c7dfb26c92343.html [2023.8]. 1 paper accepted to TACL.

[2023.7]. Receive the outstanding reviewer award for ACL 2023.

[2023.5]. Start my summer internship at SRI International (NJ). [2023.5]. 4 papers accepted to ACL 2023 (3 findings).-->
# News
[2024.5]. 1 paper accepted to ICML 2024.

[2024.3]. 2 papers accepted to NAACL 2024 (1 outstanding paper award).

[2024.2]. 1 paper accepted to CVPR 2024.

[2024.2]. Will serve as an Area Chair/Action Editor for ACL/ARR.

[2024.1]. 2 papers accepted to ICLR 2024.

[2023]. ......



# Bio
I'm a second-year CS Ph.D. student at UIUC. I'm advised by Prof. [Heng Ji](http://blender.cs.illinois.edu/hengji.html) and I also collaborate with Prof. [Hao Peng](https://haopeng-nlp.github.io/).
The long-term goal of my research is to build aligned and interactive AI systems to address challenges that remain unresolved even for human capabilities. To achieve this goal, my current research primarily concentrates on multimodal and large language models, aiming to establish fundamental approaches to address the following challenges:
- **Alignment**: How to train AI systems to follow human intents and values?
- **Interaction**: How to train AI systems to effectively interact with external entities (e.g., tools, humans) in the environment to facilitate the acquisition of information and language feedback?
- **Supervision**: How to train and evaluate AI systems that surpass the capabilities of human counterparts?





In my undergraduate years, I was a research intern at [THUNLP](https://nlp.csai.tsinghua.edu.cn) advised by Prof. [Zhiyuan Liu](http://nlp.csai.tsinghua.edu.cn/~lzy/). In the early stages of my research, I worked closely with Dr. [Fanchao Qi](https://fanchao-qi.github.io/) and received great help from him. Also, I am delighted to work with Prof. [Wei Wei](https://www.eric-weiwei.com) and Prof. [Dawn Song](https://people.eecs.berkeley.edu/~dawnsong/). 



I'm excited about the discussion and collaboration! Feel free to drop me an email if you are interested or have questions about my work.



# Selected Publications 
[[Full Publications](./publications.html)] 

**<sup>\*</sup>  indicates equal contribution <sup>\+</sup>  indicates corresponding author**

- **SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales** [[paper](https://arxiv.org/abs/2405.20974)] <br/> Tianyang Xu<sup>\*</sup>, Shujin Wu<sup>\*</sup>, Shizhe Diao, Xiaoze Liu, Xingyao Wang, **Yangyi Chen<sup>\+</sup>**, Jing Gao<sup>\+</sup> <br/> **Arxiv 2024**

- **Executable Code Actions Elicit Better LLM Agents** [[paper](https://arxiv.org/abs/2402.01030)] <br/> Xingyao Wang, **Yangyi Chen**, Lifan Yuan, Yizhe Zhang, Yunzhu Li, Hao Peng, Heng Ji <br/> **ICML 2024**

- **DRESS: Instructing Large Vision-Language Models to Align and Interact with Humans via Natural Language Feedback** [[paper](http://arxiv.org/abs/2311.10081)] <br/> **Yangyi Chen**, Karan Sikka, Michael Cogswell, Heng Ji, Ajay Divakaran <br/> **CVPR 2024**

- **CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets** [[paper](https://arxiv.org/abs/2309.17428)] <br/> Lifan Yuan<sup>\*</sup>, **Yangyi Chen**<sup>\*</sup>, Xingyao Wang, Yi R. Fung, Hao Peng, Heng Ji. <br/> **ICLR 2024**

<!--- **Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models** [[paper](https://arxiv.org/abs/2309.04461)] <br/> **Yangyi Chen**, Karan Sikka, Michael Cogswell, Heng Ji, Ajay Divakaran. <br/> **NAACL 2024** -->

- **A Close Look into the Calibration of Pre-trained Language Models** [[paper](https://arxiv.org/abs/2211.00151)] <br/> **Yangyi Chen<sup>\*</sup>**, Lifan Yuan<sup>\*</sup>, Ganqu Cui, Zhiyuan Liu, Heng Ji. <br/> **ACL 2023** 

<!-- - **Why Should Adversarial Perturbations be Imperceptible? Rethink the Research Paradigm in Adversarial NLP** [[paper](https://arxiv.org/abs/2210.10683)] <br/> **Yangyi Chen<sup>\*</sup>**, Hongcheng Gao<sup>\*</sup>, Ganqu Cui, Fanchao Qi, Longtao Huang, Zhiyuan Liu, Maosong Sun.  <br/> **EMNLP 2022** -->





# Education
- University of Illinois Urbana-Champaign, Ph.D. in Computer Science; 2022-Present

- Huazhong University of Science and Technology, BS in Software Engineering;    2018-2022

# Experience
- Amazon@Palo Alto, Applied Scientist Research Intern; May-Present 2024; Hosted by Dr. [Binxuan Huang](https://binxuan.github.io/).

- SRI International@New Jersey, Research Intern; May-Aug 2023; Hosted by Dr. [Karan Sikka](https://www.ksikka.com/), Dr. [Michael Cogswell](http://mcogswell.io/), and Dr. [Ajay Divakaran](https://www.sri.com/bios/ajay-divakaran/).

# Service
## Area Chair/Action Editor
**2024**: ACL/ARR (Feb), ARR (Apr)

## Reviewer
**2024**: COLM, ICML

**2023**: ICLR, EMNLP, EMNLP Industry Track, NeurIPS, NeurIPS D&B Track, ARR (Feb, Apr, Jun, Aug, Oct, Dec), ACL (**Outstanding Award**), IEEE T-IFS 

**2022**: NeurIPS D&B Track, EMNLP, ARR (Dec)

**Assistant**: AAAI 2022, ARR 2022 (Jan), EMNLP 2021, ARR 2021 (Oct, Nov) 
<!-- **Reviewer**: NeurIPS 2023, ARR 2023 (Feb, Apr), ACL 2023, IEEE T-IFS, NeurIPS 2022, EMNLP 2022, ARR 2022 (Dec) My research goal is to develop general-purpose models that can follow human instructions to solve tasks in a zero- or few-shot manner. I identify two important directions towards this goal and focus my research on (1) How to effectively acquire knowledge from web-scale data? (2) How to elicit the knowledge stored in pre-trained models to perform downstream tasks? 2 papers accepted to EMNLP 2022.[2022.9]. 2 papers accepted to NeurIPS 2022 (1 Spotlight).[2022.8]. Start my PhD journey at UIUC!![2022.4]. 1 paper accepted to NAACL 2022 (findings).[2021.8]. 3 papers accepted to EMNLP 2021. [2021.5]. 2 papers accepted to ACL 2021 (1 findings).I work on multimodal and large language models, basically focusing on three high-level topics: - **Fundamental development**: How to effectively develop general-purpose pre-trained models that possess strong fundamental capabilities (e.g., reasoning)?- **Exploring and exploiting their extensive potential**: How to fully leverage the capabilities of models to address real-world challenges?- **In-depth analysis**: How to systematically evaluate and interpret the behaviors of models? -->



# Personal
When I was young (around 20), I enjoyed playing the piano and basketball. When I started doing research, my interests changed and I quickly fell in love with food and soap operas. But always, I am a big fan of milk tea!! 


<!-- I enjoy playing the piano and basketball in my free time. Recently, I've been enjoying suspense/thriller movies. Finally, I've always been a big fan of milk tea!!! -->


 
